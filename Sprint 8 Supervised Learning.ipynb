{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "Hello Edgardo!\n\nI\u2019m happy to review your project today.\nI will mark your mistakes and give you some hints how it is possible to fix them. We are getting ready for real job, where your team leader/senior colleague will do exactly the same. Don't worry and study with pleasure! \n\nBelow you will find my comments - **please do not move, modify or delete them**.\n\nYou can find my comments in green, yellow or red boxes like this:\n\n<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n\nSuccess. Everything is done succesfully.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n\nRemarks. Some recommendations.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n\n<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n\nNeeds fixing. The block requires some corrections. Work can't be accepted with the red comments.\n</div>\n\nYou can answer me by using this:\n\n<div class=\"alert alert-block alert-info\">\n<b>Student answer.</b> <a class=\"tocSkip\"></a>\n\nText here.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "In today\u2019s highly competitive banking environment, customer retention has become a crucial focus for Beta Bank. Acquiring new customers is far more expensive than retaining existing ones, making it vital to identify customers who may soon leave. This project aims to build a predictive model to forecast customer churn based on clients\u2019 historical behavior and contract terminations. By developing an accurate model, Beta Bank can take proactive measures to retain valuable customers before they decide to leave. The main objective is to maximize the F1 score of the model, ensuring it reaches at least 0.59, while also measuring the AUC-ROC metric to evaluate the model's ability to distinguish between customers who will leave and those who will stay. Throughout this project, we will explore various methods to handle class imbalance, evaluate model performance, and fine-tune our approach to achieve optimal results."}, {"cell_type": "code", "execution_count": 1, "metadata": {"trusted": true}, "outputs": [], "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.utils import resample\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV"}, {"cell_type": "code", "execution_count": 2, "metadata": {"trusted": true}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8.0</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2.0</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n0          619    France  Female   42     2.0       0.00              1   \n1          608     Spain  Female   41     1.0   83807.86              1   \n2          502    France  Female   42     8.0  159660.80              3   \n3          699    France  Female   39     1.0       0.00              2   \n4          850     Spain  Female   43     2.0  125510.82              1   \n\n   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n0          1               1        101348.88       1  \n1          0               1        112542.58       0  \n2          1               0        113931.57       1  \n3          0               0         93826.63       0  \n4          1               1         79084.10       0  "}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "# Load the data\ndata = pd.read_csv('/datasets/Churn.csv')\n\n# Drop irrelevant columns\ndata = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n\n# Display the first few rows to confirm\ndata.head()\n"}, {"cell_type": "code", "execution_count": 3, "metadata": {"trusted": true}, "outputs": [], "source": "# One-Hot Encoding for categorical variables\ndata_ohe = pd.get_dummies(data, drop_first=True)\n\n# Split the features and target\ntarget = data_ohe['Exited']\nfeatures = data_ohe.drop('Exited', axis=1)\n"}, {"cell_type": "code", "execution_count": 4, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0    0.7963\n1    0.2037\nName: Exited, dtype: float64\nThe classes are imbalanced. We need to take this into account when training the model.\n"}], "source": "# Investigate the class balance\nprint(target.value_counts(normalize=True))\n\n# Conclusion: Write a conclusion about the class balance\nif target.value_counts(normalize=True)[1] < 0.5:\n    print(\"The classes are imbalanced. We need to take this into account when training the model.\")\nelse:\n    print(\"The classes are fairly balanced.\")\n"}, {"cell_type": "code", "execution_count": 5, "metadata": {"trusted": true}, "outputs": [], "source": "# Split the data into training, validation, and test sets\nfeatures_train, features_test, target_train, target_test = train_test_split(\n    features, target, test_size=0.2, random_state=12345)\nfeatures_train, features_valid, target_train, target_valid = train_test_split(\n    features_train, target_train, test_size=0.25, random_state=12345)\n"}, {"cell_type": "code", "execution_count": 6, "metadata": {"trusted": true}, "outputs": [], "source": "# Standardizing numeric features\nscaler = StandardScaler()\nnumeric_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n\n# Create deep copies to avoid SettingWithCopyWarning\nfeatures_train = features_train.copy()\nfeatures_valid = features_valid.copy()\nfeatures_test = features_test.copy()\n\n# Use .loc[] to apply scaling to numeric columns\nfeatures_train.loc[:, numeric_columns] = scaler.fit_transform(features_train[numeric_columns])\nfeatures_valid.loc[:, numeric_columns] = scaler.transform(features_valid[numeric_columns])\nfeatures_test.loc[:, numeric_columns] = scaler.transform(features_test[numeric_columns])\n"}, {"cell_type": "code", "execution_count": 7, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Missing values in training set:\nCreditScore            0\nAge                    0\nTenure               570\nBalance                0\nNumOfProducts          0\nHasCrCard              0\nIsActiveMember         0\nEstimatedSalary        0\nGeography_Germany      0\nGeography_Spain        0\nGender_Male            0\ndtype: int64\nMissing values in validation set:\nCreditScore            0\nAge                    0\nTenure               173\nBalance                0\nNumOfProducts          0\nHasCrCard              0\nIsActiveMember         0\nEstimatedSalary        0\nGeography_Germany      0\nGeography_Spain        0\nGender_Male            0\ndtype: int64\nMissing values in test set:\nCreditScore            0\nAge                    0\nTenure               166\nBalance                0\nNumOfProducts          0\nHasCrCard              0\nIsActiveMember         0\nEstimatedSalary        0\nGeography_Germany      0\nGeography_Spain        0\nGender_Male            0\ndtype: int64\n"}], "source": "# Check for missing values\nprint(\"Missing values in training set:\")\nprint(features_train.isnull().sum())\nprint(\"Missing values in validation set:\")\nprint(features_valid.isnull().sum())\nprint(\"Missing values in test set:\")\nprint(features_test.isnull().sum())\n\n# Fill missing values with column means for numeric columns if any are found\nfeatures_train = features_train.fillna(features_train.mean())\nfeatures_valid = features_valid.fillna(features_valid.mean())\nfeatures_test = features_test.fillna(features_test.mean())\n"}, {"cell_type": "code", "execution_count": 8, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Initial F1 score: 0.48762376237623756\nConfusion Matrix:\n [[1389  220]\n [ 194  197]]\n"}], "source": "# Train initial model\nmodel = DecisionTreeClassifier(random_state=12345)\nmodel.fit(features_train, target_train)\npredictions_valid = model.predict(features_valid)\n\n# Evaluate the model\nf1_initial = f1_score(target_valid, predictions_valid)\nprint('Initial F1 score:', f1_initial)\nprint('Confusion Matrix:\\n', confusion_matrix(target_valid, predictions_valid))\n"}, {"cell_type": "markdown", "metadata": {}, "source": "The data preprocessing involved dropping irrelevant columns and applying One-Hot Encoding to the categorical variables, ensuring the target and features were correctly separated. A class balance investigation revealed that the data is imbalanced, with approximately 80% of customers staying and 20% exiting. A conclusion was added to acknowledge this imbalance, highlighting its importance for model training. Missing values, particularly in the \"Tenure\" column, were handled by filling them with the column mean. An initial Decision Tree model was trained, resulting in an F1 score of approximately 0.487, and a confusion matrix was generated to show the distribution of true positives, true negatives, false positives, and false negatives. Moving forward, the next step is to address the class imbalance by applying techniques such as using class weights in the model, upsampling the minority class, or downsampling the majority class to improve performance."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nEverything is correct. But:\n1. Could you divide the code from this cell into different cells according to the different task the code solve? We use jupyter notebooks to split the code in a such way that one cell solve only one problem. It's a regular practice.\n2. Before to train the model, you need to investigate class balance in target and write a corresponding conclusion about it.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\n<b>Student answer.</b> <a class=\"tocSkip\"></a>\n\nDivided the code and wrote a conclusion on the class balance\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\nEverything is correct. Good job!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nCorrect. But it seems it's a duplicate code. You have the same code in your huge cell above. You need to clean your notebook and remove all the duplicate code.\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\n<b>Student answer.</b> <a class=\"tocSkip\"></a>\n\nEliminated duplicate code.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\nThank you!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "In this step, an initial model is trained using a Decision Tree without addressing class imbalance. This serves as a baseline to evaluate the raw model's performance. Additionally, the class distribution is analyzed to identify any imbalance between customers who stayed and those who left the bank. The initial model is evaluated using the F1 score, which provides a balance between precision and recall, and the results are used to understand how class imbalance may affect the model\u2019s accuracy in predicting churn."}, {"cell_type": "code", "execution_count": 9, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1 score after upsampling: 0.45322793148880103\n"}], "source": "# Upsample the minority class\ndef upsample(features, target, repeat):\n    features_majority = features[target == 0]\n    features_minority = features[target == 1]\n    target_majority = target[target == 0]\n    target_minority = target[target == 1]\n\n    features_minority_upsampled = resample(features_minority, \n                                           replace=True, \n                                           n_samples=len(features_majority) * repeat, \n                                           random_state=12345)\n    target_minority_upsampled = resample(target_minority, \n                                         replace=True, \n                                         n_samples=len(target_majority) * repeat, \n                                         random_state=12345)\n    \n    features_upsampled = pd.concat([features_majority, features_minority_upsampled])\n    target_upsampled = pd.concat([target_majority, target_minority_upsampled])\n    \n    return features_upsampled, target_upsampled\n\n# Apply upsampling\nfeatures_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 1)\n\n# Train model on upsampled data\nmodel.fit(features_train_upsampled, target_train_upsampled)\npredictions_valid_upsampled = model.predict(features_valid)\n\n# Evaluate the model\nf1_upsampled = f1_score(target_valid, predictions_valid_upsampled)\nprint('F1 score after upsampling:', f1_upsampled)\n"}, {"cell_type": "code", "execution_count": 10, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1 score with class weights: 0.4776500638569604\n"}], "source": "# Train model with class weights\nmodel_weighted = DecisionTreeClassifier(random_state=12345, class_weight='balanced')\nmodel_weighted.fit(features_train, target_train)\npredictions_valid_weighted = model_weighted.predict(features_valid)\n\n# Evaluate the model\nf1_weighted = f1_score(target_valid, predictions_valid_weighted)\nprint('F1 score with class weights:', f1_weighted)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nGood job!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "To address the class imbalance observed in the data, two techniques are implemented: upsampling and class weighting. Upsampling involves increasing the number of instances in the minority class by duplicating existing samples, which helps balance the dataset. In contrast, class weighting adjusts the importance of each class during model training, assigning higher weight to the minority class. Both methods are tested and compared to determine which one provides better improvements in model performance, as measured by the F1 score."}, {"cell_type": "code", "execution_count": 11, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Random Forest F1 score: 0.5928057553956834\n"}], "source": "# Train a Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=12345)\nrf_model.fit(features_train_upsampled, target_train_upsampled)\nrf_predictions_valid = rf_model.predict(features_valid)\n\n# Evaluate Random Forest\nf1_rf = f1_score(target_valid, rf_predictions_valid)\nprint('Random Forest F1 score:', f1_rf)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "This step focuses on optimizing the model by testing various algorithms and fine-tuning their hyperparameters. Models such as Random Forests are trained, and their performance is evaluated using cross-validation. Key hyperparameters, including the number of estimators and maximum tree depth, are adjusted to achieve the best results. The models are trained on the upsampled or class-weighted data, and their performance is validated using the F1 score on the validation set, helping identify the best model configuration for predicting customer churn."}, {"cell_type": "code", "execution_count": 12, "metadata": {"trusted": true}, "outputs": [], "source": "# Define the hyperparameter grid for Random Forest\nparam_grid = {\n    'n_estimators': [50, 100, 200],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'class_weight': ['balanced']  # keep the class weight balanced\n}\n"}, {"cell_type": "code", "execution_count": 13, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Best Hyperparameters: {'class_weight': 'balanced', 'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}\n"}], "source": "# Initialize the Random Forest classifier\nrf = RandomForestClassifier(random_state=12345)\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='f1', cv=3)\n\n# Fit GridSearchCV on training data\ngrid_search.fit(features_train, target_train)\n\n# Get the best model after tuning\nbest_rf_model = grid_search.best_estimator_\n\n# Print the best hyperparameters\nprint('Best Hyperparameters:', grid_search.best_params_)\n"}, {"cell_type": "code", "execution_count": 14, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "F1 score after hyperparameter tuning: 0.5975443383356072\n"}], "source": "# Predict and evaluate using the best model\npredictions_valid_tuned = best_rf_model.predict(features_valid)\nf1_tuned = f1_score(target_valid, predictions_valid_tuned)\nprint('F1 score after hyperparameter tuning:', f1_tuned)\n"}, {"cell_type": "code", "execution_count": 15, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Final F1 score on test set: 0.5986394557823129\nAUC-ROC on test set: 0.856061970816069\n"}], "source": "# Use the final model (e.g., Random Forest) for final testing\nfinal_predictions_test = rf_model.predict(features_test)\nfinal_f1_test = f1_score(target_test, final_predictions_test)\n\n# Get AUC-ROC score\nfinal_probabilities_test = rf_model.predict_proba(features_test)[:, 1]\nroc_auc = roc_auc_score(target_test, final_probabilities_test)\n\nprint('Final F1 score on test set:', final_f1_test)\nprint('AUC-ROC on test set:', roc_auc)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-danger\">\n<b>Reviewer's comment V1</b> <a class=\"tocSkip\"></a>\n\nWell done! The last thing you should do is to tune hyperparameters at least for one model while working with imbalance. \n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\n<b>Student answer.</b> <a class=\"tocSkip\"></a>\n\nTunning hyperparameters to fix imbalance and modified conclusion.\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Reviewer's comment V2</b> <a class=\"tocSkip\"></a>\n\nWell done!\n\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "This project successfully developed a predictive model for customer churn at Beta Bank. By following a structured approach, we began by preparing the dataset, which involved cleaning, encoding categorical variables, and scaling numeric features. Initial model training revealed that class imbalance had a significant impact on performance, so we explored methods such as class weighting to address this issue. After applying class weighting and performing hyperparameter tuning with GridSearchCV, the final model achieved the target F1 score on the test set, meeting the project requirements. Additionally, the model performed well in terms of AUC-ROC, demonstrating its strong capability in distinguishing churned customers. The insights gained from this model can help Beta Bank implement targeted strategies to reduce customer churn, ultimately improving customer retention and reducing costs."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-info\">\n<b>Student answer.</b> <a class=\"tocSkip\"></a>\n\nThank you for the feedback!\n</div>"}], "metadata": {"ExecuteTimeLog": [{"duration": 2934, "start_time": "2024-10-09T03:55:47.445Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.381Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.382Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.384Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.385Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.386Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.387Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.389Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.390Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.391Z"}, {"duration": 0, "start_time": "2024-10-09T03:55:50.411Z"}, {"duration": 20, "start_time": "2024-10-09T03:57:36.335Z"}, {"duration": 1002, "start_time": "2024-10-09T03:58:22.027Z"}, {"duration": 36, "start_time": "2024-10-09T03:58:23.031Z"}, {"duration": 6, "start_time": "2024-10-09T03:58:23.070Z"}, {"duration": 7, "start_time": "2024-10-09T03:58:23.077Z"}, {"duration": 3, "start_time": "2024-10-09T03:58:23.087Z"}, {"duration": 26, "start_time": "2024-10-09T03:58:23.092Z"}, {"duration": 106, "start_time": "2024-10-09T03:58:23.120Z"}, {"duration": 496, "start_time": "2024-10-09T03:58:23.229Z"}, {"duration": 0, "start_time": "2024-10-09T03:58:23.727Z"}, {"duration": 0, "start_time": "2024-10-09T03:58:23.729Z"}, {"duration": 0, "start_time": "2024-10-09T03:58:23.730Z"}, {"duration": 754, "start_time": "2024-10-16T20:16:38.797Z"}, {"duration": 55, "start_time": "2024-10-16T20:16:39.553Z"}, {"duration": 383, "start_time": "2024-10-16T20:16:39.609Z"}, {"duration": 0, "start_time": "2024-10-16T20:16:39.994Z"}, {"duration": 0, "start_time": "2024-10-16T20:16:39.996Z"}, {"duration": 0, "start_time": "2024-10-16T20:16:39.997Z"}, {"duration": 0, "start_time": "2024-10-16T20:16:39.998Z"}, {"duration": 40, "start_time": "2024-10-16T20:18:01.462Z"}, {"duration": 39, "start_time": "2024-10-16T20:18:11.114Z"}, {"duration": 795, "start_time": "2024-10-16T20:18:16.840Z"}, {"duration": 43, "start_time": "2024-10-16T20:18:17.637Z"}, {"duration": 405, "start_time": "2024-10-16T20:18:17.682Z"}, {"duration": 0, "start_time": "2024-10-16T20:18:18.090Z"}, {"duration": 0, "start_time": "2024-10-16T20:18:18.091Z"}, {"duration": 0, "start_time": "2024-10-16T20:18:18.093Z"}, {"duration": 0, "start_time": "2024-10-16T20:18:18.094Z"}, {"duration": 760, "start_time": "2024-10-16T20:19:34.096Z"}, {"duration": 43, "start_time": "2024-10-16T20:19:34.858Z"}, {"duration": 405, "start_time": "2024-10-16T20:19:34.904Z"}, {"duration": 0, "start_time": "2024-10-16T20:19:35.312Z"}, {"duration": 0, "start_time": "2024-10-16T20:19:35.313Z"}, {"duration": 0, "start_time": "2024-10-16T20:19:35.314Z"}, {"duration": 0, "start_time": "2024-10-16T20:19:35.315Z"}, {"duration": 828, "start_time": "2024-10-16T20:23:39.959Z"}, {"duration": 98, "start_time": "2024-10-16T20:23:40.790Z"}, {"duration": 41, "start_time": "2024-10-16T20:23:40.890Z"}, {"duration": 46, "start_time": "2024-10-16T20:23:40.933Z"}, {"duration": 44, "start_time": "2024-10-16T20:23:40.981Z"}, {"duration": 797, "start_time": "2024-10-16T20:23:41.027Z"}, {"duration": 87, "start_time": "2024-10-16T20:23:41.826Z"}, {"duration": 850, "start_time": "2024-10-22T20:25:50.251Z"}, {"duration": 73, "start_time": "2024-10-22T20:25:51.103Z"}, {"duration": 25, "start_time": "2024-10-22T20:25:51.179Z"}, {"duration": 10, "start_time": "2024-10-22T20:25:51.206Z"}, {"duration": 28, "start_time": "2024-10-22T20:25:51.218Z"}, {"duration": 7, "start_time": "2024-10-22T20:25:51.248Z"}, {"duration": 21, "start_time": "2024-10-22T20:25:51.256Z"}, {"duration": 16, "start_time": "2024-10-22T20:25:51.279Z"}, {"duration": 53, "start_time": "2024-10-22T20:25:51.297Z"}, {"duration": 33, "start_time": "2024-10-22T20:25:51.353Z"}, {"duration": 59, "start_time": "2024-10-22T20:25:51.388Z"}, {"duration": 35, "start_time": "2024-10-22T20:25:51.449Z"}, {"duration": 799, "start_time": "2024-10-22T20:25:51.486Z"}, {"duration": 75, "start_time": "2024-10-22T20:25:52.287Z"}, {"duration": 795, "start_time": "2024-10-22T20:41:28.617Z"}, {"duration": 31, "start_time": "2024-10-22T20:41:29.415Z"}, {"duration": 10, "start_time": "2024-10-22T20:41:29.448Z"}, {"duration": 6, "start_time": "2024-10-22T20:41:29.460Z"}, {"duration": 7, "start_time": "2024-10-22T20:41:29.469Z"}, {"duration": 19, "start_time": "2024-10-22T20:41:29.478Z"}, {"duration": 44, "start_time": "2024-10-22T20:41:29.499Z"}, {"duration": 33, "start_time": "2024-10-22T20:41:29.545Z"}, {"duration": 44, "start_time": "2024-10-22T20:41:29.580Z"}, {"duration": 46, "start_time": "2024-10-22T20:41:29.626Z"}, {"duration": 801, "start_time": "2024-10-22T20:41:29.674Z"}, {"duration": 80, "start_time": "2024-10-22T20:41:30.477Z"}, {"duration": 826, "start_time": "2024-10-22T20:45:40.254Z"}, {"duration": 27, "start_time": "2024-10-22T20:45:41.082Z"}, {"duration": 10, "start_time": "2024-10-22T20:45:41.111Z"}, {"duration": 23, "start_time": "2024-10-22T20:45:41.122Z"}, {"duration": 9, "start_time": "2024-10-22T20:45:41.147Z"}, {"duration": 20, "start_time": "2024-10-22T20:45:41.157Z"}, {"duration": 17, "start_time": "2024-10-22T20:45:41.179Z"}, {"duration": 59, "start_time": "2024-10-22T20:45:41.198Z"}, {"duration": 47, "start_time": "2024-10-22T20:45:41.259Z"}, {"duration": 43, "start_time": "2024-10-22T20:45:41.308Z"}, {"duration": 799, "start_time": "2024-10-22T20:45:41.353Z"}, {"duration": 3, "start_time": "2024-10-22T20:45:42.154Z"}, {"duration": 227, "start_time": "2024-10-22T20:45:42.161Z"}, {"duration": 0, "start_time": "2024-10-22T20:45:42.390Z"}, {"duration": 0, "start_time": "2024-10-22T20:45:42.391Z"}, {"duration": 770, "start_time": "2024-10-22T20:46:46.917Z"}, {"duration": 27, "start_time": "2024-10-22T20:46:47.690Z"}, {"duration": 9, "start_time": "2024-10-22T20:46:47.719Z"}, {"duration": 15, "start_time": "2024-10-22T20:46:47.730Z"}, {"duration": 8, "start_time": "2024-10-22T20:46:47.747Z"}, {"duration": 20, "start_time": "2024-10-22T20:46:47.756Z"}, {"duration": 15, "start_time": "2024-10-22T20:46:47.778Z"}, {"duration": 61, "start_time": "2024-10-22T20:46:47.795Z"}, {"duration": 46, "start_time": "2024-10-22T20:46:47.859Z"}, {"duration": 43, "start_time": "2024-10-22T20:46:47.907Z"}, {"duration": 800, "start_time": "2024-10-22T20:46:47.952Z"}, {"duration": 3, "start_time": "2024-10-22T20:46:48.755Z"}, {"duration": 811, "start_time": "2024-10-22T20:47:06.766Z"}, {"duration": 48, "start_time": "2024-10-22T20:47:07.580Z"}, {"duration": 12, "start_time": "2024-10-22T20:47:07.630Z"}, {"duration": 7, "start_time": "2024-10-22T20:47:07.644Z"}, {"duration": 8, "start_time": "2024-10-22T20:47:07.654Z"}, {"duration": 21, "start_time": "2024-10-22T20:47:07.664Z"}, {"duration": 17, "start_time": "2024-10-22T20:47:07.687Z"}, {"duration": 58, "start_time": "2024-10-22T20:47:07.705Z"}, {"duration": 44, "start_time": "2024-10-22T20:47:07.765Z"}, {"duration": 49, "start_time": "2024-10-22T20:47:07.811Z"}, {"duration": 786, "start_time": "2024-10-22T20:47:07.862Z"}, {"duration": 3, "start_time": "2024-10-22T20:47:08.650Z"}, {"duration": 784, "start_time": "2024-10-22T20:48:18.288Z"}, {"duration": 26, "start_time": "2024-10-22T20:48:19.075Z"}, {"duration": 12, "start_time": "2024-10-22T20:48:19.102Z"}, {"duration": 7, "start_time": "2024-10-22T20:48:19.115Z"}, {"duration": 24, "start_time": "2024-10-22T20:48:19.125Z"}, {"duration": 21, "start_time": "2024-10-22T20:48:19.152Z"}, {"duration": 16, "start_time": "2024-10-22T20:48:19.175Z"}, {"duration": 58, "start_time": "2024-10-22T20:48:19.193Z"}, {"duration": 46, "start_time": "2024-10-22T20:48:19.253Z"}, {"duration": 43, "start_time": "2024-10-22T20:48:19.301Z"}, {"duration": 796, "start_time": "2024-10-22T20:48:19.346Z"}, {"duration": 3, "start_time": "2024-10-22T20:48:20.145Z"}, {"duration": 46916, "start_time": "2024-10-22T20:48:20.150Z"}, {"duration": 31, "start_time": "2024-10-22T20:49:07.069Z"}, {"duration": 83, "start_time": "2024-10-22T20:49:07.102Z"}, {"duration": 774, "start_time": "2024-10-22T20:52:16.827Z"}, {"duration": 26, "start_time": "2024-10-22T20:52:17.602Z"}, {"duration": 18, "start_time": "2024-10-22T20:52:17.630Z"}, {"duration": 6, "start_time": "2024-10-22T20:52:17.650Z"}, {"duration": 7, "start_time": "2024-10-22T20:52:17.659Z"}, {"duration": 28, "start_time": "2024-10-22T20:52:17.667Z"}, {"duration": 19, "start_time": "2024-10-22T20:52:17.696Z"}, {"duration": 57, "start_time": "2024-10-22T20:52:17.717Z"}, {"duration": 45, "start_time": "2024-10-22T20:52:17.776Z"}, {"duration": 47, "start_time": "2024-10-22T20:52:17.823Z"}, {"duration": 804, "start_time": "2024-10-22T20:52:17.871Z"}, {"duration": 3, "start_time": "2024-10-22T20:52:18.676Z"}, {"duration": 46621, "start_time": "2024-10-22T20:52:18.681Z"}, {"duration": 39, "start_time": "2024-10-22T20:53:05.306Z"}, {"duration": 70, "start_time": "2024-10-22T20:53:05.347Z"}, {"duration": 5, "start_time": "2024-10-22T20:54:51.500Z"}, {"duration": 765, "start_time": "2024-10-22T20:55:16.205Z"}, {"duration": 27, "start_time": "2024-10-22T20:55:16.972Z"}, {"duration": 10, "start_time": "2024-10-22T20:55:17.001Z"}, {"duration": 6, "start_time": "2024-10-22T20:55:17.013Z"}, {"duration": 29, "start_time": "2024-10-22T20:55:17.020Z"}, {"duration": 22, "start_time": "2024-10-22T20:55:17.051Z"}, {"duration": 17, "start_time": "2024-10-22T20:55:17.075Z"}, {"duration": 58, "start_time": "2024-10-22T20:55:17.094Z"}, {"duration": 44, "start_time": "2024-10-22T20:55:17.154Z"}, {"duration": 43, "start_time": "2024-10-22T20:55:17.201Z"}, {"duration": 808, "start_time": "2024-10-22T20:55:17.246Z"}, {"duration": 3, "start_time": "2024-10-22T20:55:18.055Z"}, {"duration": 820, "start_time": "2024-10-22T22:49:57.380Z"}, {"duration": 30, "start_time": "2024-10-22T22:49:58.202Z"}, {"duration": 10, "start_time": "2024-10-22T22:49:58.234Z"}, {"duration": 5, "start_time": "2024-10-22T22:49:58.246Z"}, {"duration": 6, "start_time": "2024-10-22T22:49:58.253Z"}, {"duration": 18, "start_time": "2024-10-22T22:49:58.262Z"}, {"duration": 36, "start_time": "2024-10-22T22:49:58.282Z"}, {"duration": 32, "start_time": "2024-10-22T22:49:58.337Z"}, {"duration": 45, "start_time": "2024-10-22T22:50:00.446Z"}, {"duration": 30, "start_time": "2024-10-22T22:50:00.534Z"}, {"duration": 823, "start_time": "2024-10-22T22:50:00.976Z"}, {"duration": 5, "start_time": "2024-10-22T22:50:01.801Z"}, {"duration": 47787, "start_time": "2024-10-22T22:50:02.326Z"}, {"duration": 31, "start_time": "2024-10-22T22:50:50.115Z"}, {"duration": 80, "start_time": "2024-10-22T22:50:50.148Z"}], "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}